
https://www.terraform.io/


Executable written in golang
  - terraform file holds infrastructure build
    - can be split between several files for modularity
  - terraform state file (created when running terraform)
  - terraform preferences

# define credentials using variables
ex.
  variable "aws_access_key" {}
  variable "aws_secret_key" {}

# aws called provider, credentials defined there

provider "aws" {
  access_key = "access_key"
  secret_key = "secret_key"
  region = "us-east-1"
}

# server, etc called resource
#  resource details can be hard-coded or set via variables

resource "aws_instance" "ex" {
  ami = "ami-c58c1dd3"
  instance_type = "t2.micro"
}

# get info from deployment

output "aws_public_ip" {
  value = "${aws_instance.ex.public_dns}"
}


## Breakdown of a Sample terraform file
## START OF FILE

################################################################################
# VARIABLES
# MAP NOTE:  set variables  for  Access / Secret / Private (.pem) Keys and path
################################################################################

variable "aws_access_key" {}
variable "aws_secret_key" {}
variable "private_key_path" {}
variable "key_name" {
  default = "PluralsightKeys"
}

################################################################################
# PROVIDERS
# MAP NOTE:  set the provider i.e. AWS
################################################################################

provider "aws" {
  access_key = "${var.aws_access_key}"
  secret_key = "${var.aws_secret_key}"
  region     = "us-east-1"
}

################################################################################
# RESOURCES
# MAP NOTE:  set resource to create (i.e. ec2 t2.micro instance)
#              - amazon machine image
#              - instance type
#              - key name
#            set the connection and private key path (user / private key)
#            set the provisioner (how / what to install)
################################################################################

resource "aws_instance" "nginx" {
  ami           = "ami-c58c1dd3"
  instance_type = "t2.micro"
  key_name        = "${var.key_name}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.private_key_path)}"
  }

  provisioner "remote-exec" {
    inline = [
      "sudo yum install nginx -y",
      "sudo service nginx start"
    ]
  }
}

################################################################################
# OUTPUT
# MAP NOTE:  capture specific output output (i.e. DNS)
################################################################################

output "aws_instance_public_dns" {
    value = "${aws_instance.nginx.public_dns}"
}

## END OF FILE

NOTE: The above file is located in scratch/moduleone.tf

## Steps to run terraform and create AWS instances
##

## 1. Run terraform plan (from scratch directory)
##
## NOTE: terraform.tfvars holds key variable settings
scratch/> terraform plan -var-file=../vars/terraform.tfvars

## NOTE: below is the output generated stating what terraform plan would do

Refreshing Terraform state in-memory prior to plan...
The refreshed state will be used to calculate this plan, but will not be
persisted to local or remote state storage.


------------------------------------------------------------------------

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  + create

Terraform will perform the following actions:

  + aws_instance.nginx
      id:                           <computed>
      ami:                          "ami-c58c1dd3"
      associate_public_ip_address:  <computed>
      availability_zone:            <computed>
      ebs_block_device.#:           <computed>
      ephemeral_block_device.#:     <computed>
      get_password_data:            "false"
      instance_state:               <computed>
      instance_type:                "t2.micro"
      ipv6_address_count:           <computed>
      ipv6_addresses.#:             <computed>
      key_name:                     "Terraform_key.pem"
      network_interface.#:          <computed>
      network_interface_id:         <computed>
      password_data:                <computed>
      placement_group:              <computed>
      primary_network_interface_id: <computed>
      private_dns:                  <computed>
      private_ip:                   <computed>
      public_dns:                   <computed>
      public_ip:                    <computed>
      root_block_device.#:          <computed>
      security_groups.#:            <computed>
      source_dest_check:            "true"
      subnet_id:                    <computed>
      tenancy:                      <computed>
      volume_tags.%:                <computed>
      vpc_security_group_ids.#:     <computed>


Plan: 1 to add, 0 to change, 0 to destroy.

------------------------------------------------------------------------

Note: You didn't specify an "-out" parameter to save this plan, so Terraform
can't guarantee that exactly these actions will be performed if
"terraform apply" is subsequently run.




## 2. Apply the terraform plan
##
scratch/> terraform apply -var-file=../vars/terraform.tfvars
## NOTE: below is the output generated stating what terraform apply did
##       A couple of things to note:
##        - First is the output at the bottom of the run, this is the DNS that
##          was requested and is the public dns name of the nginx instance that
##          was spun up.
##               aws_instance_public_dns = ec2-75-101-179-144.compute-1.amazonaws.com
##
##        - There was an inital failure with the terraform apply, this issue was
##          an ssh timeout.  I had to update the inbound rules of the default
##          security group of the default vpc to allow traffic only from my IP
##          address.  Once this was done then the apply continued to success
##          NOTICE the bottom of the plan shows 1 to add and 1 to destroy.
##          Terraform destroyed the incomplete instance and then created a new one.
##          Plan: 1 to add, 0 to change, 1 to destroy.
##
## NOTE: changes are idempotent, which means if there is no change to configuration
##       then no changes would be done.




scratch/> terraform apply -var-file=../vars/terraform.tfvars
aws_instance.nginx: Refreshing state... (ID: i-0e31ebd11e8589a77)

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
-/+ destroy and then create replacement

Terraform will perform the following actions:

-/+ aws_instance.nginx (tainted) (new resource required)
      id:                           "i-0e31ebd11e8589a77" => <computed> (forces new resource)
      ami:                          "ami-c58c1dd3" => "ami-c58c1dd3"
      associate_public_ip_address:  "true" => <computed>
      availability_zone:            "us-east-1d" => <computed>
      ebs_block_device.#:           "0" => <computed>
      ephemeral_block_device.#:     "0" => <computed>
      get_password_data:            "false" => "false"
      instance_state:               "running" => <computed>
      instance_type:                "t2.micro" => "t2.micro"
      ipv6_address_count:           "" => <computed>
      ipv6_addresses.#:             "0" => <computed>
      key_name:                     "Terraform_key" => "Terraform_key"
      network_interface.#:          "0" => <computed>
      network_interface_id:         "eni-2a261db3" => <computed>
      password_data:                "" => <computed>
      placement_group:              "" => <computed>
      primary_network_interface_id: "eni-2a261db3" => <computed>
      private_dns:                  "ip-172-31-28-28.ec2.internal" => <computed>
      private_ip:                   "172.31.28.28" => <computed>
      public_dns:                   "ec2-54-85-203-171.compute-1.amazonaws.com" => <computed>
      public_ip:                    "54.85.203.171" => <computed>
      root_block_device.#:          "1" => <computed>
      security_groups.#:            "1" => <computed>
      source_dest_check:            "true" => "true"
      subnet_id:                    "subnet-5469540d" => <computed>
      tenancy:                      "default" => <computed>
      volume_tags.%:                "0" => <computed>
      vpc_security_group_ids.#:     "1" => <computed>


Plan: 1 to add, 0 to change, 1 to destroy.

Do you want to perform these actions?
  Terraform will perform the actions described above.
  Only 'yes' will be accepted to approve.

  Enter a value: yes

aws_instance.nginx: Destroying... (ID: i-0e31ebd11e8589a77)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 10s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 20s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 30s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 40s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 50s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0e31ebd11e8589a77, 1m0s elapsed)
aws_instance.nginx: Destruction complete after 1m1s
aws_instance.nginx: Creating...
  ami:                          "" => "ami-c58c1dd3"
  associate_public_ip_address:  "" => "<computed>"
  availability_zone:            "" => "<computed>"
  ebs_block_device.#:           "" => "<computed>"
  ephemeral_block_device.#:     "" => "<computed>"
  get_password_data:            "" => "false"
  instance_state:               "" => "<computed>"
  instance_type:                "" => "t2.micro"
  ipv6_address_count:           "" => "<computed>"
  ipv6_addresses.#:             "" => "<computed>"
  key_name:                     "" => "Terraform_key"
  network_interface.#:          "" => "<computed>"
  network_interface_id:         "" => "<computed>"
  password_data:                "" => "<computed>"
  placement_group:              "" => "<computed>"
  primary_network_interface_id: "" => "<computed>"
  private_dns:                  "" => "<computed>"
  private_ip:                   "" => "<computed>"
  public_dns:                   "" => "<computed>"
  public_ip:                    "" => "<computed>"
  root_block_device.#:          "" => "<computed>"
  security_groups.#:            "" => "<computed>"
  source_dest_check:            "" => "true"
  subnet_id:                    "" => "<computed>"
  tenancy:                      "" => "<computed>"
  volume_tags.%:                "" => "<computed>"
  vpc_security_group_ids.#:     "" => "<computed>"
aws_instance.nginx: Still creating... (10s elapsed)
aws_instance.nginx: Still creating... (20s elapsed)
aws_instance.nginx: Still creating... (30s elapsed)
aws_instance.nginx: Still creating... (40s elapsed)
aws_instance.nginx: Still creating... (50s elapsed)
aws_instance.nginx: Still creating... (1m0s elapsed)
aws_instance.nginx: Provisioning with 'remote-exec'...
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx: Still creating... (1m10s elapsed)
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx: Still creating... (1m20s elapsed)
aws_instance.nginx: Still creating... (1m30s elapsed)
aws_instance.nginx (remote-exec): Connecting to remote host via SSH...
aws_instance.nginx (remote-exec):   Host: 75.101.179.144
aws_instance.nginx (remote-exec):   User: ec2-user
aws_instance.nginx (remote-exec):   Password: false
aws_instance.nginx (remote-exec):   Private key: true
aws_instance.nginx (remote-exec):   SSH Agent: true
aws_instance.nginx (remote-exec):   Checking Host Key: false
aws_instance.nginx (remote-exec): Connected!
aws_instance.nginx (remote-exec): Loaded plugins: priorities, update-motd,
aws_instance.nginx (remote-exec):               : upgrade-helper
aws_instance.nginx (remote-exec): Resolving Dependencies
aws_instance.nginx (remote-exec): --> Running transaction check
aws_instance.nginx (remote-exec): ---> Package nginx.x86_64 1:1.12.1-1.33.amzn1 will be installed
aws_instance.nginx (remote-exec): --> Processing Dependency: libcrypto.so.10(OPENSSL_1.0.2)(64bit) for package: 1:nginx-1.12.1-1.33.amzn1.x86_64
aws_instance.nginx (remote-exec): --> Processing Dependency: libprofiler.so.0()(64bit) for package: 1:nginx-1.12.1-1.33.amzn1.x86_64
aws_instance.nginx (remote-exec): --> Running transaction check
aws_instance.nginx (remote-exec): ---> Package gperftools-libs.x86_64 0:2.0-11.5.amzn1 will be installed
aws_instance.nginx (remote-exec): --> Processing Dependency: libunwind.so.8()(64bit) for package: gperftools-libs-2.0-11.5.amzn1.x86_64
aws_instance.nginx (remote-exec): ---> Package openssl.x86_64 1:1.0.1k-15.99.amzn1 will be updated
aws_instance.nginx (remote-exec): ---> Package openssl.x86_64 1:1.0.2k-8.107.amzn1 will be an update
aws_instance.nginx (remote-exec): --> Running transaction check
aws_instance.nginx (remote-exec): ---> Package libunwind.x86_64 0:1.1-10.8.amzn1 will be installed
aws_instance.nginx (remote-exec): --> Finished Dependency Resolution

aws_instance.nginx (remote-exec): Dependencies Resolved

aws_instance.nginx (remote-exec): ========================================
aws_instance.nginx (remote-exec):  Package   Arch   Version
aws_instance.nginx (remote-exec):                      Repository    Size
aws_instance.nginx (remote-exec): ========================================
aws_instance.nginx (remote-exec): Installing:
aws_instance.nginx (remote-exec):  nginx     x86_64 1:1.12.1-1.33.amzn1
aws_instance.nginx (remote-exec):                      amzn-main    561 k
aws_instance.nginx (remote-exec): Installing for dependencies:
aws_instance.nginx (remote-exec):  gperftools-libs
aws_instance.nginx (remote-exec):            x86_64 2.0-11.5.amzn1
aws_instance.nginx (remote-exec):                      amzn-main    570 k
aws_instance.nginx (remote-exec):  libunwind x86_64 1.1-10.8.amzn1
aws_instance.nginx (remote-exec):                      amzn-main     72 k
aws_instance.nginx (remote-exec): Updating for dependencies:
aws_instance.nginx (remote-exec):  openssl   x86_64 1:1.0.2k-8.107.amzn1
aws_instance.nginx (remote-exec):                      amzn-updates 1.8 M

aws_instance.nginx (remote-exec): Transaction Summary
aws_instance.nginx (remote-exec): ========================================
aws_instance.nginx (remote-exec): Install  1 Package  (+2 Dependent packages)
aws_instance.nginx (remote-exec): Upgrade             ( 1 Dependent package)

aws_instance.nginx (remote-exec): Total download size: 2.9 M
aws_instance.nginx (remote-exec): Downloading packages:
aws_instance.nginx (remote-exec): (1/4): libunwind-1 |  72 kB   00:00
aws_instance.nginx (remote-exec): (3/4): nginx-1 15% | 474 kB   --:-- ETA
aws_instance.nginx (remote-exec): (2/4): gperftools- | 570 kB   00:00
aws_instance.nginx (remote-exec): (3/4): nginx-1.12. | 561 kB   00:00
aws_instance.nginx (remote-exec): (4/4): openssl 53% | 1.6 MB   00:01 ETA
aws_instance.nginx (remote-exec): (4/4): openssl-1.0 | 1.8 MB   00:00
aws_instance.nginx (remote-exec): ----------------------------------------
aws_instance.nginx (remote-exec): Total      2.7 MB/s | 2.9 MB  00:01
aws_instance.nginx (remote-exec): Running transaction check
aws_instance.nginx (remote-exec): Running transaction test
aws_instance.nginx (remote-exec): Transaction test succeeded
aws_instance.nginx (remote-exec): Running transaction
aws_instance.nginx (remote-exec):   Updating   : 1:openss [         ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [#        ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [##       ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [###      ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [####     ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [#####    ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [######   ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [#######  ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openss [######## ] 1/5
aws_instance.nginx (remote-exec):   Updating   : 1:openssl-1.0.2k-8   1/5
aws_instance.nginx (remote-exec):   Installing : libunwin [         ] 2/5
aws_instance.nginx (remote-exec):   Installing : libunwin [#####    ] 2/5
aws_instance.nginx (remote-exec):   Installing : libunwin [#######  ] 2/5
aws_instance.nginx (remote-exec):   Installing : libunwin [######## ] 2/5
aws_instance.nginx (remote-exec):   Installing : libunwind-1.1-10.8   2/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [         ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [#        ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [##       ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [###      ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [####     ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [#####    ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [######   ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [#######  ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftoo [######## ] 3/5
aws_instance.nginx (remote-exec):   Installing : gperftools-libs-2.   3/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [         ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [#        ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [##       ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [###      ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [####     ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [#####    ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [######   ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [#######  ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx- [######## ] 4/5
aws_instance.nginx (remote-exec):   Installing : 1:nginx-1.12.1-1.3   4/5
aws_instance.nginx (remote-exec):   Cleanup    : 1:openssl-1.0.1k-1   5/5
aws_instance.nginx (remote-exec):   Verifying  : libunwind-1.1-10.8   1/5
aws_instance.nginx (remote-exec):   Verifying  : gperftools-libs-2.   2/5
aws_instance.nginx (remote-exec):   Verifying  : 1:nginx-1.12.1-1.3   3/5
aws_instance.nginx (remote-exec):   Verifying  : 1:openssl-1.0.2k-8   4/5
aws_instance.nginx (remote-exec):   Verifying  : 1:openssl-1.0.1k-1   5/5

aws_instance.nginx (remote-exec): Installed:
aws_instance.nginx (remote-exec):   nginx.x86_64 1:1.12.1-1.33.amzn1

aws_instance.nginx (remote-exec): Dependency Installed:
aws_instance.nginx (remote-exec):   gperftools-libs.x86_64 0:2.0-11.5.amzn1
aws_instance.nginx (remote-exec):   libunwind.x86_64 0:1.1-10.8.amzn1

aws_instance.nginx (remote-exec): Dependency Updated:
aws_instance.nginx (remote-exec):   openssl.x86_64 1:1.0.2k-8.107.amzn1

aws_instance.nginx (remote-exec): Complete!
aws_instance.nginx (remote-exec): Starting nginx:          [  OK  ]
aws_instance.nginx: Creation complete after 1m37s (ID: i-0d37238bddb1e8776)

Apply complete! Resources: 1 added, 0 changed, 1 destroyed.

Outputs:

aws_instance_public_dns = ec2-75-101-179-144.compute-1.amazonaws.com



## 3. Tear down the aws resources that were created via destroy
##
scratch/> terraform destroy -var-file=../vars/terraform.tfvars

aws_instance.nginx: Refreshing state... (ID: i-0d37238bddb1e8776)

An execution plan has been generated and is shown below.
Resource actions are indicated with the following symbols:
  - destroy

Terraform will perform the following actions:

  - aws_instance.nginx


Plan: 0 to add, 0 to change, 1 to destroy.

Do you really want to destroy?
  Terraform will destroy all your managed infrastructure, as shown above.
  There is no undo. Only 'yes' will be accepted to confirm.

  Enter a value: yes

aws_instance.nginx: Destroying... (ID: i-0d37238bddb1e8776)
aws_instance.nginx: Still destroying... (ID: i-0d37238bddb1e8776, 10s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0d37238bddb1e8776, 20s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0d37238bddb1e8776, 30s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0d37238bddb1e8776, 40s elapsed)
aws_instance.nginx: Still destroying... (ID: i-0d37238bddb1e8776, 50s elapsed)
aws_instance.nginx: Destruction complete after 54s

Destroy complete! Resources: 1 destroyed.

#######################################################################
## Terraform State
#######################################################################

Terraform keeps state in a json file: terraform.tfstate
  - contains resource mappings and metadata
    builds resource and dependency tree

  - When changes are being done to configuration, state file becomes locked so
    that only one person can make change to a resource at a time.

  - State file can be stored locally or remotely
      - remote storage of state files:
          - consul
          - aws s3

  - Can store state file to dev / prod files from same terraform file

Terraform Planning:
  - Terraform inspects state and can refresh from current state of resource
  - Terraform inspects configuration file
  - Creates dependency graph
      - what resources deployed
      - what order to deploy
      - creates dependency tree (subnets created after vpc created)
      - determines additions / deletions configuration change will make to
        the dependency graph
      - walks dependency graph and implements determined changes (adds / deletes)



## Terraform Data Sources
## Build a configuration with data outside of terraform
## NOTE: providers are responsible for defining data sources
##       data type is first  parm (aws_availability_zones)
##       data name is second parm (aws_availability_zones)

data "aws_availability_zones" "available" {}

## This sets up a data source by querying aws availability zones and returning the
## data to a variable called available

resource "aws_subnet" "subnet1" {
  cidr_block        = "${var.subnet1_address_space}"
  vpc_id            = "${aws_vpc.vpc.id}"
  availability_zone = "${data.aws_availability_zones.available.names[0]}"

}

This shows a subnet be declared as subnet1 and setting the availability_zone to
the data source declared earlier = ${data.aws_availability_zones.available.names[0]}


## create security group and elb using the created security group
##


# Nginx security group
resource "aws_security_group" "nginx-sg" {
  name        = "nginx_sg"
  vpc_id      = "${aws_vpc.vpc.id}"

  ingress {}
  egress {}
}

# elb based w/ sec grp created above
resource "aws_elb" "web" {
  name = "nginx-elb"
  security_groups = ["${aws_security_group.elb-sg.id}"]
}



################################################################################
## More complicated example
################################################################################

Here we will be creating an infrastructure that has:
  - a vpc
  - internet gateway
  - two subnets
  - route tables (and route table associations)
  - security groups
  - two web servers
  - an elb

This example is done in two parts (START, UPDATE).  Comments on what is happening
in each section will be done via NOTE:


### START
  ##################################################################################
  # VARIABLES
  # NOTE:  key variables delcared. Network address space declared for vpc and
  # NOTE:  the two subnets.
  ##################################################################################

  variable "aws_access_key" {}
  variable "aws_secret_key" {}
  variable "private_key_path" {}
  variable "key_name" {
    default = "PluralsightKeys"
  }
  variable "network_address_space" {
    default = "10.1.0.0/16"
  }
  variable "subnet1_address_space" {
    default = "10.1.0.0/24"
  }
  variable "subnet2_address_space" {
    default = "10.1.1.0/24"
  }

  ##################################################################################
  # PROVIDERS
  # NOTE:  Setting the provider for the resources and data.
  # NOTE:  Setting up w/ keys and region
  ##################################################################################

  provider "aws" {
    access_key = "${var.aws_access_key}"
    secret_key = "${var.aws_secret_key}"
    region     = "us-east-1"
  }

  ##################################################################################
  # DATA
  # NOTE:  Sets Data Type for available availability zones for region provided
  ##################################################################################

  data "aws_availability_zones" "available" {}

  ##################################################################################
  # RESOURCES
  ##################################################################################

  # NETWORKING #
  # NOTE:  Networking resources setup:
  # NOTE:  - vpc
  # NOTE:  - internet gateway
  # NOTE:  - subnet1 / subnet 2
  # NOTE:  - route table / route table association (link tbl to subnet)
  # NOTE:  - security group: setting ingress (22, 80) and egress (0) traffic
  #
  resource "aws_vpc" "vpc" {
    cidr_block = "${var.network_address_space}"
    enable_dns_hostnames = "true"

  }

  resource "aws_internet_gateway" "igw" {
    vpc_id = "${aws_vpc.vpc.id}"

  }

  resource "aws_subnet" "subnet1" {
    cidr_block        = "${var.subnet1_address_space}"
    vpc_id            = "${aws_vpc.vpc.id}"
    map_public_ip_on_launch = "true"
    availability_zone = "${data.aws_availability_zones.available.names[0]}"

  }

  resource "aws_subnet" "subnet2" {
    cidr_block        = "${var.subnet2_address_space}"
    vpc_id            = "${aws_vpc.vpc.id}"
    map_public_ip_on_launch = "true"
    availability_zone = "${data.aws_availability_zones.available.names[1]}"

  }

  # ROUTING #
  resource "aws_route_table" "rtb" {
    vpc_id = "${aws_vpc.vpc.id}"

    route {
      cidr_block = "0.0.0.0/0"
      gateway_id = "${aws_internet_gateway.igw.id}"
    }
  }

  resource "aws_route_table_association" "rta-subnet1" {
    subnet_id      = "${aws_subnet.subnet1.id}"
    route_table_id = "${aws_route_table.rtb.id}"
  }

  resource "aws_route_table_association" "rta-subnet2" {
    subnet_id      = "${aws_subnet.subnet2.id}"
    route_table_id = "${aws_route_table.rtb.id}"
  }

  # SECURITY GROUPS #
  # Nginx security group
  resource "aws_security_group" "nginx-sg" {
    name        = "nginx_sg"
    vpc_id      = "${aws_vpc.vpc.id}"

    # SSH access from anywhere
    ingress {
      from_port   = 22
      to_port     = 22
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }

    # HTTP access from anywhere
    ingress {
      from_port   = 80
      to_port     = 80
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }

    # outbound internet access
    egress {
      from_port   = 0
      to_port     = 0
      protocol    = "-1"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  # INSTANCES #
  # NOTE:  aws instance, set with type, subnet, sec group, key name
  # NOTE:  connection and a provisioner to install and set services and files
  #
  resource "aws_instance" "nginx1" {
    ami           = "ami-c58c1dd3"
    instance_type = "t2.micro"
    subnet_id     = "${aws_subnet.subnet1.id}"
    vpc_security_group_ids = ["${aws_security_group.nginx-sg.id}"]
    key_name        = "${var.key_name}"

    connection {
      user        = "ec2-user"
      private_key = "${file(var.private_key_path)}"
    }

    provisioner "remote-exec" {
      inline = [
        "sudo yum install nginx -y",
        "sudo service nginx start",
        "echo '<html><head><title>Blue Team Server</title></head><body style=\"background-color:#1F778D\"><p style=\"text-align: center;\"><span style=\"color:#FFFFFF;\"><span style=\"font-size:28px;\">Blue Team</span></span></p></body></html>' | sudo tee /usr/share/nginx/html/index.html"
      ]
    }
  }

  ##################################################################################
  # OUTPUT
  # NOTE:  get the public DNS name of the nginx instance
  ##################################################################################

  output "aws_instance_public_dns" {
      value = "${aws_instance.nginx1.public_dns}"
  }





## UPDATE
## NOTE:  Here are the differences between moduletwo-start.tf and
## NOTE:  moduletwo-update.tf.ignore
##

map@hexagon:/mod2/> diff moduletwo-start.tf moduletwo-update.tf.ignore  |  pg
44d43
## NOTE:  First thing to note is that the vpc loses the enable_dns_hostnames
## NOTE:  The thinking here is that with load blancer and iwg it is not needed.
<   enable_dns_hostnames = "true"
89a89,109
## NOTE:  Next thing that is created is a new security group for the elb.
> resource "aws_security_group" "elb-sg" {
>   name        = "nginx_elb_sg"
>   vpc_id      = "${aws_vpc.vpc.id}"
>
>   #Allow HTTP from anywhere
>   ingress {
>     from_port   = 80
>     to_port     = 80
>     protocol    = "tcp"
>     cidr_blocks = ["0.0.0.0/0"]
>   }
>
>   #allow all outbound
>   egress {
>     from_port   = 0
>     to_port     = 0
>     protocol    = "-1"
>     cidr_blocks = ["0.0.0.0/0"]
>   }
> }
>
103c123
## NOTE:  The nginx security group is then updated to have the HTTP ingress
## NOTE:  traffic only come from the network_address_space, hence only network
## NOTE:  traffic from the VPC (due to the igw and load balancer)
<   # HTTP access from anywhere
---
>   # HTTP access from the VPC
108c128
<     cidr_blocks = ["0.0.0.0/0"]
---
>     cidr_blocks = ["${var.network_address_space}"]
119a140,155
## NOTE:  Next a elb is created called nginx-elb.  This will be the load balancer
## NOTE:  for the two web servers.  The ports are set and the subnets are set to
## NOTE:  the two subnets.  The security group is set to the nginx_elb_sg and the
## NOTE:  instances point to the aws instances nginx1 and nginx2.
> # LOAD BALANCER #
> resource "aws_elb" "web" {
>   name = "nginx-elb"
>
>   subnets         = ["${aws_subnet.subnet1.id}", "${aws_subnet.subnet2.id}"]
>   security_groups = ["${aws_security_group.elb-sg.id}"]
>   instances       = ["${aws_instance.nginx1.id}", "${aws_instance.nginx2.id}"]
>
>   listener {
>     instance_port     = 80
>     instance_protocol = "http"
>     lb_port           = 80
>     lb_protocol       = "http"
>   }
> }
>
141a178,198
## NOTE:  Next to last a new web instance is created named nginx2. This uses
## NOTE:  subnet2 and the nginx-sg secuirty group.  It also provisions nginx,
## NOTE:  starts the sevices and updates the index.html
##
> resource "aws_instance" "nginx2" {
>   ami           = "ami-c58c1dd3"
>   instance_type = "t2.micro"
>   subnet_id     = "${aws_subnet.subnet2.id}"
>   vpc_security_group_ids = ["${aws_security_group.nginx-sg.id}"]
>   key_name        = "${var.key_name}"
>
>   connection {
>     user        = "ec2-user"
>     private_key = "${file(var.private_key_path)}"
>   }
>
>   provisioner "remote-exec" {
>     inline = [
>       "sudo yum install nginx -y",
>       "sudo service nginx start",
>       "echo '<html><head><title>Green Team Server</title></head><body style=\"background-color:#77A032\"><p style=\"text-align: center;\"><span style=\"color:#FFFFFF;\"><span style=\"font-size:28px;\">Green Team</span></span></p></body></html>' | sudo tee /usr/share/nginx/html/index.html"
>     ]
>   }
> }
>
146,147c203,204
## NOTE:  Lastly, the output is not the nginx1 public dns (remember the vpc
## NOTE:  value was updated to not allow it).  The output value is the
## NOTE:  is the elb public dns name.
##
< output "aws_instance_public_dns" {
<     value = "${aws_instance.nginx1.public_dns}"
---
> output "aws_elb_public_dns" {
>     value = "${aws_elb.web.dns_name}"



################################################################################
## Configuring Resources After Creation
################################################################################

Provisioners:  Plug into resources to perform actions as that resource is being created.

Updates to Scenario:
  - export logs from webservers to s3
  - drop website files into s3 and have web servers import them as their config
  - add tags to resources with billing account



################################################################################
## Provisioners
################################################################################
  - Multiple uses
  - Local or remote
  - Provisioner can be executed during creation or destruction (?)
  - Can use multiple provisioners in a single resource (file vs. remote-exec)
      - If something goes wrong with provisioner the resource is in an
        inconsistent state.
      - Terraform flags that resource as tainted but continues processing


provisioner ex.

## tells provisioner how to connect
##
connection {
  user = "username"
  private_key = "privatekey"
}

## Creates a file on the destination resource
##
provisioner "file" {
  content = <<EOF
 your file content goes in raw here
EOF
  destination = "/path/to/file.txt"
}


## Runs command locally (windows or linux)
##
provisioner "local-exec" {
  command = "local command here"
}

## Remote exec runs commands remotely (yum, etc.)
## NOTE: You can provide a list of scripts that are available locally and
## NOTE: remote-exec will copy them to the remote resource and execute them remotely.
##
provisioner "remote-exec" {
  scripts = "[list, of local, scripts, to, run]"
}



################################################################################
## Terraform Syntax
################################################################################

Terraform uses HashiCorp configuration language.
  - this converts to JSON to the providers

Interpolation:   interpolation syntax allows you to reference variables,
                 attributes of resources, call functions.
                 These interpolations are wrapped in ${}, such as ${var.foo}.

Conditionals: if/then do/while
functions:    take a value/ produce output
templates:    datasource you design, a long string of text that is consumable by terraform$a


## Create a variable
##
variable var_name {
  key = value #type, default, description
}

## NOTE: you do not have to immediately give a variable a value
##       when you give the variable a value terraform will determine the type by
##       the value given to it


## Use a variable
##
${var.name}         # get string
${var.map["key"]}   # get map element
${var.list[ids]}    # get list element


## Create provider
##
provider provider_name {
  key = value # depends on resource use alias as needed
}
## NOTE: alias allows you to create multiples of same provider
##       i.e. east-us-1  vs. west-us-1

## Create data object
## NOTE:  data object pulls information from a provider for use later
##
data data_type data_name {}

## Use data object
${data_type.data_name.attributes(args)}


## Create resource
##
resource  resource_type resource_name {
  key = value   # depends on resource
}

## Reference resource
##
${resource_type.resource_name.attribute(args)}


################################################################################
## Examine
## Breakdown of a mod3 terraform file, logs, tags, etc
## Observations will be done via NOTE: comments
################################################################################

## START OF FILE

################################################################################
# VARIABLES
################################################################################

variable "aws_access_key" {}
variable "aws_secret_key" {}
variable "private_key_path" {}
variable "key_name" {
  default = "Terraform_key"
}
variable "network_address_space" {
  default = "10.1.0.0/16"
}
variable "subnet1_address_space" {
  default = "10.1.0.0/24"
}
variable "subnet2_address_space" {
  default = "10.1.1.0/24"
}

## NOTE:  access and subnets same as previously, variables setup
##        billing_code_tag, environment_tag and bucket_name
##
variable "billing_code_tag" {}
variable "environment_tag" {}
variable "bucket_name" {}

################################################################################
# PROVIDERS
################################################################################

provider "aws" {
  access_key = "${var.aws_access_key}"
  secret_key = "${var.aws_secret_key}"
  region     = "us-east-1"
}

################################################################################
# DATA
################################################################################

data "aws_availability_zones" "available" {}

################################################################################
# RESOURCES
################################################################################

# NETWORKING #
## NOTE: Notice the tag section of the vpc resource.  Values are
##       dynamically assigned from variable and static values i.e.
##              Name = "${var.environment_tag}-vpc"
##       Tags are applied to:  vpc, igw, subnet1, subnet2, route table
##       (but not route table association rta-subnet1,2), secruity groups
##       (elb-sg, nginx-sg), load balancer,  aws instance (nginx1,2),
##       s3 bucket
##
resource "aws_vpc" "vpc" {
  cidr_block = "${var.network_address_space}"

  tags {
    Name = "${var.environment_tag}-vpc"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

resource "aws_internet_gateway" "igw" {
  vpc_id = "${aws_vpc.vpc.id}"

  tags {
    Name = "${var.environment_tag}-igw"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

resource "aws_subnet" "subnet1" {
  cidr_block        = "${var.subnet1_address_space}"
  vpc_id            = "${aws_vpc.vpc.id}"
  map_public_ip_on_launch = "true"
  availability_zone = "${data.aws_availability_zones.available.names[0]}"

  tags {
    Name = "${var.environment_tag}-subnet1"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

resource "aws_subnet" "subnet2" {
  cidr_block        = "${var.subnet2_address_space}"
  vpc_id            = "${aws_vpc.vpc.id}"
  map_public_ip_on_launch = "true"
  availability_zone = "${data.aws_availability_zones.available.names[1]}"

  tags {
    Name = "${var.environment_tag}-subnet2"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

# ROUTING #
resource "aws_route_table" "rtb" {
  vpc_id = "${aws_vpc.vpc.id}"

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = "${aws_internet_gateway.igw.id}"
  }

  tags {
    Name = "${var.environment_tag}-rtb"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

resource "aws_route_table_association" "rta-subnet1" {
  subnet_id      = "${aws_subnet.subnet1.id}"
  route_table_id = "${aws_route_table.rtb.id}"
}

resource "aws_route_table_association" "rta-subnet2" {
  subnet_id      = "${aws_subnet.subnet2.id}"
  route_table_id = "${aws_route_table.rtb.id}"
}

# SECURITY GROUPS #
resource "aws_security_group" "elb-sg" {
  name        = "nginx_elb_sg"
  vpc_id      = "${aws_vpc.vpc.id}"

  #Allow HTTP from anywhere
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  #allow all outbound
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags {
    Name = "${var.environment_tag}-elb-sg"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

# Nginx security group
resource "aws_security_group" "nginx-sg" {
  name        = "nginx_sg"
  vpc_id      = "${aws_vpc.vpc.id}"

  # SSH access from anywhere
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # HTTP access from the VPC
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["${var.network_address_space}"]
  }

  # outbound internet access
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags {
    Name = "${var.environment_tag}-nginx-sg"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

# LOAD BALANCER #
resource "aws_elb" "web" {
  name = "nginx-elb"

  subnets         = ["${aws_subnet.subnet1.id}", "${aws_subnet.subnet2.id}"]
  security_groups = ["${aws_security_group.elb-sg.id}"]
  instances       = ["${aws_instance.nginx1.id}", "${aws_instance.nginx2.id}"]

  listener {
    instance_port     = 80
    instance_protocol = "http"
    lb_port           = 80
    lb_protocol       = "http"
  }

  tags {
    Name = "${var.environment_tag}-elb"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

# INSTANCES #
## NOTE: Notice provisioners attached to the resource. First two are file resources
##       that set an s3cmd config file and a nginx log configuration file. The
##       third provisioner is a remote-exec provisioner that runs multiple
##       to set up the environment, the website files from s3 bucket and sets
##       up logging to s3
##

resource "aws_instance" "nginx1" {
  ami           = "ami-c58c1dd3"
  instance_type = "t2.micro"
  subnet_id     = "${aws_subnet.subnet1.id}"
  vpc_security_group_ids = ["${aws_security_group.nginx-sg.id}"]
  key_name        = "${var.key_name}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.private_key_path)}"
  }

  provisioner "file" {
    content = <<EOF
access_key = ${aws_iam_access_key.write_user.id}
secret_key = ${aws_iam_access_key.write_user.secret}
use_https = True
bucket_location = US

EOF
    destination = "/home/ec2-user/.s3cfg"
  }

  provisioner "file" {
    content = <<EOF
/var/log/nginx/*log {
    daily
    rotate 10
    missingok
    compress
    sharedscripts
    postrotate
      INSTANCE_ID=`curl --silent http://169.254.169.254/latest/meta-data/instance-id`
      /usr/local/bin/s3cmd sync /var/log/nginx/access.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
      /usr/local/bin/s3cmd sync /var/log/nginx/error.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
    endscript
}

EOF
    destination = "/home/ec2-user/nginx"
  }

  provisioner "remote-exec" {
    inline = [
      "sudo yum install nginx -y",
      "sudo service nginx start",
      "sudo cp /home/ec2-user/.s3cfg /root/.s3cfg",
      "sudo cp /home/ec2-user/nginx /etc/logrotate.d/nginx",
      "sudo pip install s3cmd",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/index.html .",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/Globo_logo_Vert.png .",
      "sudo cp /home/ec2-user/index.html /usr/share/nginx/html/index.html",
      "sudo cp /home/ec2-user/Globo_logo_Vert.png /usr/share/nginx/html/Globo_logo_Vert.png",
      "sudo logrotate -f /etc/logrotate.conf"

    ]
  }

  tags {
    Name = "${var.environment_tag}-nginx1"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

resource "aws_instance" "nginx2" {
  ami           = "ami-c58c1dd3"
  instance_type = "t2.micro"
  subnet_id     = "${aws_subnet.subnet2.id}"
  vpc_security_group_ids = ["${aws_security_group.nginx-sg.id}"]
  key_name        = "${var.key_name}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.private_key_path)}"
  }

  provisioner "file" {
    content = <<EOF
access_key = ${aws_iam_access_key.write_user.id}
secret_key = ${aws_iam_access_key.write_user.secret}
use_https = True
bucket_location = US

EOF
    destination = "/home/ec2-user/.s3cfg"
  }

  provisioner "file" {
    content = <<EOF
/var/log/nginx/*log {
    daily
    rotate 10
    missingok
    compress
    sharedscripts
    postrotate
      INSTANCE_ID=`curl --silent http://169.254.169.254/latest/meta-data/instance-id`
      /usr/local/bin/s3cmd sync /var/log/nginx/access.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
      /usr/local/bin/s3cmd sync /var/log/nginx/error.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
    endscript
}

EOF
    destination = "/home/ec2-user/nginx"
  }

  provisioner "remote-exec" {
    inline = [
      "sudo yum install nginx -y",
      "sudo service nginx start",
      "sudo cp /home/ec2-user/.s3cfg /root/.s3cfg",
      "sudo cp /home/ec2-user/nginx /etc/logrotate.d/nginx",
      "sudo pip install s3cmd",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/index.html .",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/Globo_logo_Vert.png .",
      "sudo cp /home/ec2-user/index.html /usr/share/nginx/html/index.html",
      "sudo cp /home/ec2-user/Globo_logo_Vert.png /usr/share/nginx/html/Globo_logo_Vert.png",
      "sudo logrotate -f /etc/logrotate.conf"

    ]
  }

  tags {
    Name = "${var.environment_tag}-nginx2"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

# S3 Bucket config#
## NOTE: aws iam user created called write_user, which is  given an s3 policy
##       to write to the bucket

resource "aws_iam_user" "write_user" {
    name = "${var.environment_tag}-s3-write-user"
    force_destroy = true
}

resource "aws_iam_access_key" "write_user" {
    user = "${aws_iam_user.write_user.name}"
}

resource "aws_iam_user_policy" "write_user_pol" {
    name = "write"
    user = "${aws_iam_user.write_user.name}"
    policy= <<EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}",
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
            ]
        }
   ]
}
EOF

}

## NOTE: s3 bucket is created  called "${var.environment_tag}-${var.bucket_name}"
##       (this becomes dev-iamwhatiam-s3-test).  Assigns policy to bucket also.
##

resource "aws_s3_bucket" "web_bucket" {
  bucket = "${var.environment_tag}-${var.bucket_name}"
  acl = "private"
  force_destroy = true

      policy = <<EOF
{
    "Version": "2008-10-17",
    "Statement": [
        {
            "Sid": "PublicReadForGetBucketObjects",
            "Effect": "Allow",
            "Principal": {
                "AWS": "*"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Principal": {
                "AWS": "${aws_iam_user.write_user.arn}"
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}",
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
            ]
        }
    ]
}
EOF

  tags {
    Name = "${var.environment_tag}-web_bucket"
    BillingCode        = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }

}

## NOTE: Create s3 bucket objects: index.html, Globo_logo_Ver.png
##       These are used to create the website.
##
resource "aws_s3_bucket_object" "website" {
  bucket = "${aws_s3_bucket.web_bucket.bucket}"
  key    = "/website/index.html"
  source = "./index.html"

}

resource "aws_s3_bucket_object" "graphic" {
  bucket = "${aws_s3_bucket.web_bucket.bucket}"
  key    = "/website/Globo_logo_Vert.png"
  source = "./Globo_logo_Vert.png"

}

################################################################################
# OUTPUT
################################################################################

output "aws_elb_public_dns" {
    value = "${aws_elb.web.dns_name}"
}


## END OF FILE



################################################################################
## Adding a new provicer to your configuration
## (multiple clouds)
################################################################################

## Terraform Providers
##

 - Open source using Public APIs
 - Made up of resource and data sources
    - resource:     aws instance you can create
    - data source:  az can pull information from
 - Can have multiple instances for providers


  1. Community Providers
      - Community developed provider
        - Digital Ocean
        - VMWare
        - GitHub
        - Docker
        - etc
  2. HashiCorp Providers
      - HashiCorp developed provider
        - AWS
        - Azure
        - GCP
        - Oracle






## How to setup multiple instances of the same provider
## i.e. east vs west instance
## Utilize the alias field in the provider configuration and
##


provider "aws" {
  access_key = "access_key"
  secret_key = "secret_key"
  region = "us-east-1"
  alias = "east"
}

provider "aws" {
  access_key = "access_key"
  secret_key = "secret_key"
  region = "us-west-1"
  alias = "west"
}

resource "aws_instance" "nginx_east" {
  provider      = "aws.east"
  ami           = "ami-c58c1dd3"
  instance_type = "t2.micro"
  key_name        = "${var.key_name}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.private_key_path)}"
  }
}

resource "aws_instance" "nginx_west" {
  provider      = "aws.west"
  ami           = "ami-46e1f226"
  instance_type = "t2.micro"
  key_name        = "${var.key_name_west}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.west_private_key_path)}"
  }
}



## Azure Provider overview
## azurerm = Azure Resource Manager
## NOTE: azurerm has ALL locations available as a provider
##       Do Not Need Multiple Providers for different locations (like aws)

provider "azurerm" {
  subscription_id = "subscription-id"
  client_id =  "principal-used-for-access"
  client_secret = "password-of-principal"
  tenant_id =  "tenant-id"
  alias =  "arm-1"
}

## resource group: container that any other resource created resides in
##
resource "azurerm_resource_group" {
  name = "resource-group-name"
  location = "East US"
  provider = "azurerm.arm-1
}





################################################################################
## Terraform functions
################################################################################

Conditionals and functions
ex.
      - abs
      - basename
      - cidrhost
      - contains
      - element
      - file
      - format
      - join
      - length
      - map
      - etc
uses:
string manipulation
counter

## Function Examples
##

## Configure networking
variable network_info {
  default = "10.0.0.0/8" #type, default, description
}

## Returns 10.1.0.0/16
cidr_block = ${cidrsubnet(var.network_info,8,1)}

## Returns 10.2.0.0/16
cidr_block = ${cidrsubnet(var.network_info,8,2)}


## Create ami map
##

variable "amis" {
  type = "map"
  default = {
    us-east-1 = "ami-1234"
    us-west-1 = "ami-5678"
  }
}

## lookup the key in the map to get the ami
##
ami = ${lookup(var.amis, "us-east-1")}






################################################################################
## Examine
## Breakdown of mod4 terraform file: aws + azure
## Observations will be done via NOTE: comments
################################################################################

## START OF FILE


################################################################################
# VARIABLES
################################################################################

variable "aws_access_key" {}
variable "aws_secret_key" {}
variable "private_key_path" {}

variable "key_name" {
  default = "PluralsightKeys"
}

variable "network_address_space" {
  default = "10.1.0.0/16"
}

variable "billing_code_tag" {}
variable "environment_tag" {}
variable "bucket_name" {}

## NOTE:  Azure Resource Manager variable
##        minimum needed to access azure:
##        subcription_id, principal, password, tenant_id
##
variable "arm_subscription_id" {}
variable "arm_principal" {}
variable "arm_password" {}
variable "tenant_id" {}
variable "dns_zone_name" {}
variable "dns_resource_group" {}

## NOTE:  instance_count: number of instances to create in a subnet
##        subnet_count:   number of subnets to create
##
## NOTE:  Value will be overridden if variable is declare in variable file or
##        or at the command line.
##
variable "instance_count" {
  default = 2
}

variable "subnet_count" {
  default = 2
}

################################################################################
# PROVIDERS
################################################################################

provider "aws" {
  access_key = "${var.aws_access_key}"
  secret_key = "${var.aws_secret_key}"
  region     = "us-east-1"
}

## NOTE:  Setting up Azure Resource Manager provider
##        alias is set to arm-1
##
provider "azurerm" {
  subscription_id = "${var.arm_subscription_id}"
  client_id       = "${var.arm_principal}"
  client_secret   = "${var.arm_password}"
  tenant_id       = "${var.tenant_id}"
  alias           = "arm-1"
}

################################################################################
# DATA
################################################################################

data "aws_availability_zones" "available" {}

################################################################################
# RESOURCES
################################################################################

# NETWORKING #
resource "aws_vpc" "vpc" {
  cidr_block = "${var.network_address_space}"

  tags {
    Name        = "${var.environment_tag}-vpc"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

resource "aws_internet_gateway" "igw" {
  vpc_id = "${aws_vpc.vpc.id}"

  tags {
    Name        = "${var.environment_tag}-igw"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

## NOTE:  Notice the count setting in aws_subnet. This acts like a loop
##        and will create "count" many resources of this type. Also notice
##        that it is referencing subnet_count declared previously.
##
##        count is also being reference in the cidr_block declaration.  Here it
##        is using the count.index which would be the loop index of count at
##        that time.  In this case it referrig to the cidr network number to
##        return back.
##
##        availability_zone is using count.index to chose from list of az.
##
##        The tags => Name is also using the count.index to create the name of
##        the subnet.
##
resource "aws_subnet" "subnet" {
  count                   = "${var.subnet_count}"
  cidr_block              = "${cidrsubnet(var.network_address_space, 8, count.index + 1)}"
  vpc_id                  = "${aws_vpc.vpc.id}"
  map_public_ip_on_launch = "true"
  availability_zone       = "${data.aws_availability_zones.available.names[count.index]}"

  tags {
    Name        = "${var.environment_tag}-subnet-${count.index + 1}"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

# ROUTING #
resource "aws_route_table" "rtb" {
  vpc_id = "${aws_vpc.vpc.id}"

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = "${aws_internet_gateway.igw.id}"
  }

  tags {
    Name        = "${var.environment_tag}-rtb"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

## NOTE:  How to reference the "X" number of subnets created by loop ??
##        In route table association, count is being set by variable subnet_count.
##        subnet_id is being assigned from aws_subnet.subnet (which has multiple elements)
##        subnet_id is being assigned from aws_subnet.subnet (which has
##        multiple elements) and is getting the index item back and then assigning
##        that to route table
##
##        In short this is looping thru subnet_count and assigning from element
##        to a subnet_id variable and then assigning that subnet_id variable to
##        route table.
##
## NOTE:  The element function takes a list of objects.  This is provided by
##        the wildcard (*) pattern in aws_subnet.subnet.*.id.  This brings back
##        a list of all if subnet_ids which are then iterated thru and assigned
##        to the route table.  Looping context and list processing.
##
resource "aws_route_table_association" "rta-subnet" {
  count          = "${var.subnet_count}"
  subnet_id      = "${element(aws_subnet.subnet.*.id,count.index)}"
  route_table_id = "${aws_route_table.rtb.id}"
}

# SECURITY GROUPS #
resource "aws_security_group" "elb-sg" {
  name   = "nginx_elb_sg"
  vpc_id = "${aws_vpc.vpc.id}"

  #Allow HTTP from anywhere
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  #allow all outbound
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags {
    Name        = "${var.environment_tag}-elb-sg"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

# Nginx security group
resource "aws_security_group" "nginx-sg" {
  name   = "nginx_sg"
  vpc_id = "${aws_vpc.vpc.id}"

  # SSH access from anywhere
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }

  # HTTP access from the VPC
  ingress {
    from_port   = 80
    to_port     = 80
    protocol    = "tcp"
    cidr_blocks = ["${var.network_address_space}"]
  }

  # outbound internet access
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags {
    Name        = "${var.environment_tag}-nginx-sg"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

# LOAD BALANCER #
resource "aws_elb" "web" {
  name = "nginx-elb"

  subnets         = ["${aws_subnet.subnet.*.id}"]
  security_groups = ["${aws_security_group.elb-sg.id}"]
  instances       = ["${aws_instance.nginx.*.id}"]

  listener {
    instance_port     = 80
    instance_protocol = "http"
    lb_port           = 80
    lb_protocol       = "http"
  }

  tags {
    Name        = "${var.environment_tag}-elb"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

# INSTANCES #
## NOTE:  Instance creation is looping by utilizing count = ${var.instance_count}
##        subnet_id assignment is using modulo operation so instances fall into
##        one of the subnet buckets.
##        tag Name is also using the count.index in the name.
##
## NOTE:  You can scale up or down instance by changing the count value in the
##        variable file.
##
resource "aws_instance" "nginx" {
  count                  = "${var.instance_count}"
  ami                    = "ami-c58c1dd3"
  instance_type          = "t2.micro"
  subnet_id              = "${element(aws_subnet.subnet.*.id,count.index % var.subnet_count)}"
  vpc_security_group_ids = ["${aws_security_group.nginx-sg.id}"]
  key_name               = "${var.key_name}"

  connection {
    user        = "ec2-user"
    private_key = "${file(var.private_key_path)}"
  }

  provisioner "file" {
    content = <<EOF
access_key = ${aws_iam_access_key.write_user.id}
secret_key = ${aws_iam_access_key.write_user.secret}
use_https = True
bucket_location = US

EOF

    destination = "/home/ec2-user/.s3cfg"
  }

  provisioner "file" {
    content = <<EOF
/var/log/nginx/*log {
    daily
    rotate 10
    missingok
    compress
    sharedscripts
    postrotate
      INSTANCE_ID=`curl --silent http://169.254.169.254/latest/meta-data/instance-id`
      /usr/local/bin/s3cmd sync /var/log/nginx/access.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
      /usr/local/bin/s3cmd sync /var/log/nginx/error.log-* s3://${aws_s3_bucket.web_bucket.id}/$INSTANCE_ID/nginx/
    endscript
}

EOF

    destination = "/home/ec2-user/nginx"
  }

  provisioner "remote-exec" {
    inline = [
      "sudo yum install nginx -y",
      "sudo service nginx start",
      "sudo cp /home/ec2-user/.s3cfg /root/.s3cfg",
      "sudo cp /home/ec2-user/nginx /etc/logrotate.d/nginx",
      "sudo pip install s3cmd",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/index.html .",
      "s3cmd get s3://${aws_s3_bucket.web_bucket.id}/website/Globo_logo_Vert.png .",
      "sudo cp /home/ec2-user/index.html /usr/share/nginx/html/index.html",
      "sudo cp /home/ec2-user/Globo_logo_Vert.png /usr/share/nginx/html/Globo_logo_Vert.png",
      "sudo logrotate -f /etc/logrotate.conf",
    ]
  }

  tags {
    Name        = "${var.environment_tag}-nginx-${count.index + 1}"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

# S3 Bucket config#
resource "aws_iam_user" "write_user" {
  name          = "${var.environment_tag}-s3-write-user"
  force_destroy = true
}

resource "aws_iam_access_key" "write_user" {
  user = "${aws_iam_user.write_user.name}"
}

resource "aws_iam_user_policy" "write_user_pol" {
  name = "write"
  user = "${aws_iam_user.write_user.name}"

  policy = <<EOF
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}",
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
            ]
        }
   ]
}
EOF
}

resource "aws_s3_bucket" "web_bucket" {
  bucket        = "${var.environment_tag}-${var.bucket_name}"
  acl           = "private"
  force_destroy = true

  policy = <<EOF
{
    "Version": "2008-10-17",
    "Statement": [
        {
            "Sid": "PublicReadForGetBucketObjects",
            "Effect": "Allow",
            "Principal": {
                "AWS": "*"
            },
            "Action": "s3:GetObject",
            "Resource": "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
        },
        {
            "Sid": "",
            "Effect": "Allow",
            "Principal": {
                "AWS": "${aws_iam_user.write_user.arn}"
            },
            "Action": "s3:*",
            "Resource": [
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}",
                "arn:aws:s3:::${var.environment_tag}-${var.bucket_name}/*"
            ]
        }
    ]
}
EOF

  tags {
    Name        = "${var.environment_tag}-web_bucket"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

resource "aws_s3_bucket_object" "website" {
  bucket = "${aws_s3_bucket.web_bucket.bucket}"
  key    = "/website/index.html"
  source = "./index.html"
}

resource "aws_s3_bucket_object" "graphic" {
  bucket = "${aws_s3_bucket.web_bucket.bucket}"
  key    = "/website/Globo_logo_Vert.png"
  source = "./Globo_logo_Vert.png"
}


## NOTE:  variables dns_zone_name and dns_resource_group correspond to
##        entities already created in azure and referenced in vars file.
##        In this case a dns zone name created and placed in a dns resource group.
##
## NOTE:  Here a cname DNS record is pointing back to aws elb dns name.
## NOTE:  provider is being set to alias set previously (azurerm.arm-1)
## NOTE:  tags are same between AWS and Azure !!
##
# Azure RM DNS #
resource "azurerm_dns_cname_record" "elb" {
  name                = "${var.environment_tag}-website"
  zone_name           = "${var.dns_zone_name}"
  resource_group_name = "${var.dns_resource_group}"
  ttl                 = "30"
  record              = "${aws_elb.web.dns_name}"
  provider            = "azurerm.arm-1"

  tags {
    Name        = "${var.environment_tag}-website"
    BillingCode = "${var.billing_code_tag}"
    Environment = "${var.environment_tag}"
  }
}

################################################################################
# OUTPUT
################################################################################

## NOTE:  Outputting elb.web.dns_name and azure dns cname elb.id
##
output "aws_elb_public_dns" {
  value = "${aws_elb.web.dns_name}"
}

output "azure_rm_dns_cname" {
  value = "${azurerm_dns_cname_record.elb.id}"
}


## END OF FILE


## Terraform console: utilize console to test terraform functions, etc.
##
> terraform console
> element(list("juan", "due", "thrice"), 2)
thrice
> slice(list("juan", "due", "thrice"), 0,2)
[
  "juan",
  "due",
]

## Passing in a variable at the terraform command prompt.
## This will override the default value of the variable in the terraform file
> terraform apply -var-file=../../vars/terraform.tfvars  -var instance_count=4


## Terraform Commands
##
> terraform fmt      ## reformat terraform file to canonical form
> terraform refresh  ## update local state file to capture any changes made
> terraform taint    ## manually flag a resource as tainted to force recreation
> terraform untaint  ## manually flag a resource as untainted to avoid recreation


################################################################################
# Using Variables in Deployments
################################################################################


Same configuration but each environment will have different variables.

  - variables get own .tf file
  - outputs   get own .tf file
  - resources get own or separate .tf file


Variable in a .tfvars file will override a default in a .tf file.

Variable precedence:
    - default variables            (low)
    - tfvars file variables (mid)
    - command line declared variables (highest)

Select variables dependent on environment:
    - Enviroment map using env as key:
        NUM_OF_INSTANCE['DEV'] = 1
        NUM_OF_INSTANCE['UAT'] = 2
        NUM_OF_INSTANCE['PROD'] =6

Conditionals within terraform config:
  use true/ false variable to determine if resource created


# default variable
variable enironment_name {
  default = "development"
}

# Specify variable in a file
enviroment_name = "uat"

# Specify variable in-line
terrafprm plan -var 'enviroment_name=production'

## Create variable map
##
variable cidr {
  type = "map"
  default {
    development = "10.0.0.0/16"
    uat = "10.1.0.0/16"
    prod = "10.2.0.0/16"
  }
}

# use map based on env var:
cidr_block = ${lookup(var.cidr, var.environment_name)}


## Multiple environnments variable map
##
  - state file commands
  - state file storage can be stored remotely
  - folder structure mirrors environnments


  main_config.tf
  variable.tf
  [dev folder]
  [uat folder]
  [prod folder]

  terraform apply -state="./dev/dev.state" -var="environment=dev"

## NOTE: the above places the state file into an env directory and then
##       passes in the environment variable.











##
